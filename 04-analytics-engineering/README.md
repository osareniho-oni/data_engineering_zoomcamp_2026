# Week 4: Analytics Engineering - dbt (Data Build Tool)

[![dbt](https://img.shields.io/badge/dbt-FF694B?logo=dbt&logoColor=white)](https://www.getdbt.com/)
[![SQL](https://img.shields.io/badge/SQL-CC2927?logo=microsoft-sql-server&logoColor=white)](https://en.wikipedia.org/wiki/SQL)
[![BigQuery](https://img.shields.io/badge/BigQuery-4285F4?logo=google-cloud&logoColor=white)](https://cloud.google.com/bigquery)
[![Jinja](https://img.shields.io/badge/Jinja-B41717?logo=jinja&logoColor=white)](https://jinja.palletsprojects.com/)

## ğŸ“‹ Module Overview

This module introduces **Analytics Engineering** with **dbt (Data Build Tool)**, a modern framework for transforming data in your warehouse. You'll learn to build modular, tested, and documented data transformation pipelines using SQL and Jinja templating.

### Learning Objectives
- âœ… Understand analytics engineering principles and workflows
- âœ… Build multi-layer dbt projects (staging â†’ intermediate â†’ marts)
- âœ… Create reusable SQL macros with Jinja templating
- âœ… Implement data quality tests (schema, data, custom)
- âœ… Generate and maintain data documentation
- âœ… Use incremental models for large datasets
- âœ… Apply dimensional modeling techniques (facts & dimensions)
- âœ… Version control analytics code with Git

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      RAW DATA SOURCES                            â”‚
â”‚  BigQuery Tables (from Week 2 & 3):                             â”‚
â”‚  â€¢ yellow_tripdata (20M+ records)                               â”‚
â”‚  â€¢ green_tripdata (5M+ records)                                 â”‚
â”‚  â€¢ fhv_tripdata (For-Hire Vehicle data)                         â”‚
â”‚  â€¢ taxi_zone_lookup (reference data)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ dbt source()
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      STAGING LAYER                               â”‚
â”‚  Purpose: Clean, standardize, and type-cast raw data            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  stg_yellow_tripdata.sql                                 â”‚  â”‚
â”‚  â”‚  â€¢ Rename columns to standard naming                     â”‚  â”‚
â”‚  â”‚  â€¢ Cast data types (INTEGER, NUMERIC, TIMESTAMP)         â”‚  â”‚
â”‚  â”‚  â€¢ Filter out null vendor_id                             â”‚  â”‚
â”‚  â”‚  â€¢ Add service_type = 'yellow'                           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  stg_green_tripdata.sql                                  â”‚  â”‚
â”‚  â”‚  â€¢ Same transformations as yellow                        â”‚  â”‚
â”‚  â”‚  â€¢ Add service_type = 'green'                            â”‚  â”‚
â”‚  â”‚  â€¢ Handle green-specific columns (trip_type)             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  stg_fhv_tripdata.sql                                    â”‚  â”‚
â”‚  â”‚  â€¢ For-Hire Vehicle data                                 â”‚  â”‚
â”‚  â”‚  â€¢ Different schema from yellow/green                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ dbt ref()
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INTERMEDIATE LAYER                            â”‚
â”‚  Purpose: Business logic, unions, enrichment                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  int_trips_unioned.sql                                   â”‚  â”‚
â”‚  â”‚  â€¢ UNION ALL yellow + green trips                        â”‚  â”‚
â”‚  â”‚  â€¢ Standardize column names across taxi types            â”‚  â”‚
â”‚  â”‚  â€¢ Handle schema differences                             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  int_trips.sql                                           â”‚  â”‚
â”‚  â”‚  â€¢ Generate surrogate key (trip_id)                      â”‚  â”‚
â”‚  â”‚  â€¢ Join with payment_type_lookup                         â”‚  â”‚
â”‚  â”‚  â€¢ Calculate trip_duration_minutes (macro)               â”‚  â”‚
â”‚  â”‚  â€¢ Data quality filters                                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ dbt ref()
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        MARTS LAYER                               â”‚
â”‚  Purpose: Business-ready tables for analytics & BI              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  DIMENSIONS (Slowly Changing Dimensions)                 â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚  dim_zones.sql                                     â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Zone lookup with borough info                   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Type 1 SCD (overwrite)                          â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚  dim_vendors.sql                                   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Vendor master data                              â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Hardcoded reference (seed alternative)          â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  FACTS (Transaction Tables)                              â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚  fct_trips.sql (Incremental)                       â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ All trips with enriched zone names              â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Star schema: fact + dimension joins             â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Incremental strategy for performance            â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  REPORTING (Aggregated Metrics)                          â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚  fct_monthly_zone_revenue.sql                      â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Monthly revenue by zone                         â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Pre-aggregated for dashboard performance        â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ Business KPIs (avg fare, trip count, revenue)   â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ANALYTICS & BI TOOLS                          â”‚
â”‚  â€¢ Looker / Tableau / Power BI                                  â”‚
â”‚  â€¢ Jupyter Notebooks                                            â”‚
â”‚  â€¢ Custom Applications                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
04-analytics-engineering/
â”œâ”€â”€ README.md                           # This file
â”œâ”€â”€ main.py                            # Entry point script
â”œâ”€â”€ pyproject.toml                     # Python dependencies
â”œâ”€â”€ flows/                             # Kestra workflows (data ingestion)
â”‚   â”œâ”€â”€ fhv_trip_data_2019.yaml
â”‚   â”œâ”€â”€ ingest_fhv_to_gcs.yaml
â”‚   â””â”€â”€ load_fhv_to_bq.yaml
â”œâ”€â”€ homework/                          # Assignment deliverables
â”‚   â”œâ”€â”€ best_performing_zone_for_green_taxis_2020.png
â”‚   â”œâ”€â”€ fhv_records_count.png
â”‚   â”œâ”€â”€ green_taxi_trip_counts_october_2019.png
â”‚   â””â”€â”€ Records in fct_monthly_zone_revenue.png
â”œâ”€â”€ logs/                              # dbt execution logs
â”‚   â”œâ”€â”€ dbt.log
â”‚   â””â”€â”€ query_log.sql
â””â”€â”€ taxi_rides_ny/                     # dbt project root
    â”œâ”€â”€ dbt_project.yml                # Project configuration
    â”œâ”€â”€ models/                        # SQL transformation models
    â”‚   â”œâ”€â”€ staging/                   # Layer 1: Raw data cleaning
    â”‚   â”‚   â”œâ”€â”€ sources.yml            # Source definitions
    â”‚   â”‚   â”œâ”€â”€ schema.yml             # Model documentation & tests
    â”‚   â”‚   â”œâ”€â”€ stg_yellow_tripdata.sql
    â”‚   â”‚   â”œâ”€â”€ stg_green_tripdata.sql
    â”‚   â”‚   â””â”€â”€ stg_fhv_tripdata.sql
    â”‚   â”œâ”€â”€ intermediate/              # Layer 2: Business logic
    â”‚   â”‚   â”œâ”€â”€ schema.yml
    â”‚   â”‚   â”œâ”€â”€ int_trips_unioned.sql  # Union yellow + green
    â”‚   â”‚   â””â”€â”€ int_trips.sql          # Enrichment & deduplication
    â”‚   â””â”€â”€ marts/                     # Layer 3: Analytics-ready
    â”‚       â”œâ”€â”€ schema.yml
    â”‚       â”œâ”€â”€ dim_zones.sql          # Dimension: Zones
    â”‚       â”œâ”€â”€ dim_vendors.sql        # Dimension: Vendors
    â”‚       â”œâ”€â”€ fct_trips.sql          # Fact: All trips
    â”‚       â””â”€â”€ reporting/
    â”‚           â”œâ”€â”€ schema.yml
    â”‚           â””â”€â”€ fct_monthly_zone_revenue.sql
    â”œâ”€â”€ macros/                        # Reusable SQL functions
    â”‚   â”œâ”€â”€ macros_properties.yml      # Macro documentation
    â”‚   â”œâ”€â”€ get_trip_duration_minutes.sql
    â”‚   â”œâ”€â”€ get_vendor_data.sql
    â”‚   â””â”€â”€ safe_cast.sql
    â”œâ”€â”€ seeds/                         # CSV reference data
    â”‚   â””â”€â”€ payment_type_lookup.csv
    â”œâ”€â”€ tests/                         # Custom data tests
    â”œâ”€â”€ snapshots/                     # Type 2 SCD tracking
    â”œâ”€â”€ dbt_packages/                  # Installed packages
    â”‚   â”œâ”€â”€ dbt_utils/                 # Utility macros
    â”‚   â””â”€â”€ codegen/                   # Code generation
    â””â”€â”€ target/                        # Compiled SQL (gitignored)
```

## ğŸ› ï¸ Technology Stack

| Technology | Purpose | Key Features |
|------------|---------|--------------|
| **dbt Core** | Transformation framework | SQL-based, version controlled, tested |
| **BigQuery** | Data warehouse | Serverless, scalable, SQL interface |
| **Jinja** | Templating engine | Dynamic SQL, macros, control flow |
| **Git** | Version control | Collaboration, code review, history |
| **Python** | Scripting & automation | Data ingestion, testing |

## ğŸš€ Setup & Installation

### Prerequisites

```bash
# Python 3.11+
python --version

# pip or uv package manager
pip --version
# or
uv --version
```

### Step 1: Install dbt

```bash
# Navigate to project directory
cd 04-analytics-engineering

# Install dependencies (includes dbt-bigquery)
pip install dbt-bigquery

# Or using uv
uv sync

# Verify installation
dbt --version
```

### Step 2: Configure dbt Profile

Create `~/.dbt/profiles.yml`:

```yaml
taxi_rides_ny:
  target: dev
  outputs:
    dev:
      type: bigquery
      method: service-account
      project: <YOUR_GCP_PROJECT_ID>
      dataset: dbt_gabriel  # Your dev schema
      threads: 4
      timeout_seconds: 300
      location: US
      keyfile: /path/to/service-account-key.json
      
    prod:
      type: bigquery
      method: service-account
      project: <YOUR_GCP_PROJECT_ID>
      dataset: production  # Production schema
      threads: 8
      timeout_seconds: 300
      location: US
      keyfile: /path/to/service-account-key.json
```

### Step 3: Test Connection

```bash
cd taxi_rides_ny

# Test database connection
dbt debug

# Expected output:
# Connection test: [OK connection ok]
```

### Step 4: Install dbt Packages

```bash
# Install packages defined in packages.yml
dbt deps

# This installs:
# - dbt_utils (utility macros)
# - codegen (code generation helpers)
```

## ğŸ¯ Running the Project

### Full Refresh (First Run)

```bash
cd taxi_rides_ny

# Run all models
dbt run

# Run with full refresh (rebuild incremental models)
dbt run --full-refresh

# Run specific model
dbt run --select stg_yellow_tripdata

# Run model and all downstream dependencies
dbt run --select stg_yellow_tripdata+
```

### Testing

```bash
# Run all tests
dbt test

# Test specific model
dbt test --select stg_yellow_tripdata

# Test specific test type
dbt test --select test_type:unique
dbt test --select test_type:not_null
```

### Documentation

```bash
# Generate documentation
dbt docs generate

# Serve documentation site
dbt docs serve

# Opens browser at http://localhost:8080
# Includes:
# - Lineage graph (DAG visualization)
# - Model descriptions
# - Column-level documentation
# - Test results
```

### Development Workflow

```bash
# 1. Create new model
touch models/staging/stg_new_source.sql

# 2. Develop model (use --select for faster iteration)
dbt run --select stg_new_source

# 3. Add tests in schema.yml
# 4. Run tests
dbt test --select stg_new_source

# 5. Generate documentation
dbt docs generate

# 6. Commit to Git
git add models/staging/stg_new_source.sql
git commit -m "Add new staging model"
```

## ğŸ“Š Model Examples

### Staging Model: stg_yellow_tripdata.sql

```sql
with source as (
    -- Reference raw source table
    select * from {{ source('wk1_tf_dataset', 'yellow_tripdata') }}
),

renamed as (
    select
        -- Identifiers
        cast(vendorid as integer) as vendor_id,
        {{ dbt.safe_cast('ratecodeid', 'integer') }} as rate_code_id,
        cast(pulocationid as integer) as pickup_location_id,
        cast(dolocationid as integer) as dropoff_location_id,
        
        -- Timestamps
        cast(tpep_pickup_datetime as timestamp) as pickup_datetime,
        cast(tpep_dropoff_datetime as timestamp) as dropoff_datetime,
        
        -- Trip info
        cast(store_and_fwd_flag as string) as store_and_fwd_flag,
        cast(passenger_count as integer) as passenger_count,
        cast(trip_distance as numeric) as trip_distance,
         
        -- Payment info
        cast(fare_amount as numeric) as fare_amount,
        cast(extra as numeric) as extra,
        cast(mta_tax as numeric) as mta_tax,
        cast(tip_amount as numeric) as tip_amount,
        cast(tolls_amount as numeric) as tolls_amount,
        cast(improvement_surcharge as numeric) as improvement_surcharge,
        cast(total_amount as numeric) as total_amount,
        {{ dbt.safe_cast('payment_type', 'integer') }} as payment_type,
        
        -- Add service type for union
        'yellow' as service_type

    from source
    -- Data quality: filter out null vendor_id
    where vendorid is not null
)

select * from renamed

-- dbt will compile this to:
-- CREATE OR REPLACE VIEW dbt_gabriel.stg_yellow_tripdata AS (...)
```

### Intermediate Model: int_trips.sql

```sql
with unioned as (
    select * from {{ ref('int_trips_unioned') }}
),

payment_types as (
    select * from {{ ref('payment_type_lookup') }}
),

cleaned_and_enriched as (
    select
        -- Generate surrogate key (MD5 hash of composite key)
        {{ dbt_utils.generate_surrogate_key([
            'u.vendor_id', 
            'u.pickup_datetime', 
            'u.pickup_location_id', 
            'u.service_type'
        ]) }} as trip_id,

        -- Identifiers
        u.vendor_id,
        u.service_type,
        u.rate_code_id,

        -- Locations
        u.pickup_location_id,
        u.dropoff_location_id,

        -- Timestamps
        u.pickup_datetime,
        u.dropoff_datetime,

        -- Trip details
        u.store_and_fwd_flag,
        u.passenger_count,
        u.trip_distance,
        u.trip_type,

        -- Payment breakdown
        u.fare_amount,
        u.extra,
        u.mta_tax,
        u.tip_amount,
        u.tolls_amount,
        u.improvement_surcharge,
        u.total_amount,
        u.payment_type,
        
        -- Enrichment: payment type description
        pt.description as payment_type_description,
        
        -- Calculated field using custom macro
        {{ get_trip_duration_minutes('u.pickup_datetime', 'u.dropoff_datetime') }} as trip_duration_minutes

    from unioned u
    left join payment_types pt on u.payment_type = pt.payment_type
    
    -- Data quality filters
    where u.trip_distance > 0
      and u.fare_amount > 0
      and u.pickup_datetime < u.dropoff_datetime
)

select * from cleaned_and_enriched
```

### Mart Model: fct_trips.sql (Incremental)

```sql
{{
  config(
    materialized='incremental',
    unique_key='trip_id',
    incremental_strategy='merge',
    on_schema_change='append_new_columns'
  )
}}

-- Fact table: All trips with enriched zone information
-- Star schema design: fact + dimension joins

select
    -- Trip identifiers
    trips.trip_id,
    trips.vendor_id,
    trips.service_type,
    trips.rate_code_id,

    -- Location details (enriched with zone names)
    trips.pickup_location_id,
    pz.borough as pickup_borough,
    pz.zone as pickup_zone,
    trips.dropoff_location_id,
    dz.borough as dropoff_borough,
    dz.zone as dropoff_zone,

    -- Trip timing
    trips.pickup_datetime,
    trips.dropoff_datetime,
    trips.trip_duration_minutes,

    -- Trip metrics
    trips.passenger_count,
    trips.trip_distance,
    trips.trip_type,

    -- Payment breakdown
    trips.fare_amount,
    trips.extra,
    trips.mta_tax,
    trips.tip_amount,
    trips.tolls_amount,
    trips.improvement_surcharge,
    trips.total_amount,
    trips.payment_type,
    trips.payment_type_description

from {{ ref('int_trips') }} trips
left join {{ ref('dim_zones') }} pz on trips.pickup_location_id = pz.location_id
left join {{ ref('dim_zones') }} dz on trips.dropoff_location_id = dz.location_id

{% if is_incremental() %}
    -- Only process new records since last run
    where trips.pickup_datetime > (select max(pickup_datetime) from {{ this }})
{% endif %}
```

### Reporting Model: fct_monthly_zone_revenue.sql

```sql
-- Pre-aggregated monthly revenue by zone
-- Optimized for dashboard queries

select
    -- Time dimension
    date_trunc(pickup_datetime, month) as revenue_month,
    
    -- Location dimension
    pickup_zone,
    pickup_borough,
    
    -- Service type
    service_type,
    
    -- Aggregated metrics
    count(*) as trip_count,
    sum(fare_amount) as total_fare_amount,
    sum(extra) as total_extra,
    sum(mta_tax) as total_mta_tax,
    sum(tip_amount) as total_tip_amount,
    sum(tolls_amount) as total_tolls_amount,
    sum(improvement_surcharge) as total_improvement_surcharge,
    sum(total_amount) as total_revenue,
    
    -- Calculated metrics
    avg(fare_amount) as avg_fare_amount,
    avg(trip_distance) as avg_trip_distance,
    avg(trip_duration_minutes) as avg_trip_duration_minutes

from {{ ref('fct_trips') }}
where pickup_zone is not null
group by 
    revenue_month,
    pickup_zone,
    pickup_borough,
    service_type
```

## ğŸ§ª Testing Framework

### Schema Tests (Built-in)

```yaml
# models/staging/schema.yml
version: 2

models:
  - name: stg_yellow_tripdata
    description: "Cleaned and standardized yellow taxi trip data"
    columns:
      - name: vendor_id
        description: "Taxi vendor identifier"
        tests:
          - not_null
          - accepted_values:
              values: [1, 2]
      
      - name: pickup_datetime
        description: "Trip start timestamp"
        tests:
          - not_null
      
      - name: trip_distance
        description: "Trip distance in miles"
        tests:
          - not_null
          - dbt_utils.expression_is_true:
              expression: ">= 0"
      
      - name: fare_amount
        description: "Base fare amount"
        tests:
          - not_null
          - dbt_utils.expression_is_true:
              expression: "> 0"
```

### Custom Tests

```sql
-- tests/assert_positive_trip_duration.sql
-- Custom test: Ensure trip duration is positive

select *
from {{ ref('int_trips') }}
where trip_duration_minutes <= 0
```

### Data Quality Tests

```yaml
# models/intermediate/schema.yml
models:
  - name: int_trips
    tests:
      # Uniqueness test
      - dbt_utils.unique_combination_of_columns:
          combination_of_columns:
            - trip_id
      
      # Referential integrity
      - dbt_utils.relationships_where:
          to: ref('dim_zones')
          field: location_id
          from_condition: pickup_location_id is not null
    
    columns:
      - name: trip_id
        tests:
          - unique
          - not_null
      
      - name: pickup_datetime
        tests:
          - not_null
          - dbt_utils.expression_is_true:
              expression: "< dropoff_datetime"
```

## ğŸ”§ Custom Macros

### Macro: get_trip_duration_minutes.sql

```sql
{#
    Calculate trip duration in minutes from pickup and dropoff timestamps.
    Uses dbt's built-in cross-database datediff macro.
    Works across DuckDB, BigQuery, Snowflake, Redshift, PostgreSQL.
#}

{% macro get_trip_duration_minutes(pickup_datetime, dropoff_datetime) %}
    {{ dbt.datediff(pickup_datetime, dropoff_datetime, 'minute') }}
{% endmacro %}

-- Usage in model:
-- {{ get_trip_duration_minutes('pickup_datetime', 'dropoff_datetime') }}
```

### Macro: get_vendor_data.sql

```sql
{#
    Return vendor name based on vendor_id.
    Demonstrates conditional logic in macros.
#}

{% macro get_vendor_data(vendor_id) %}
    case {{ vendor_id }}
        when 1 then 'Creative Mobile Technologies'
        when 2 then 'VeriFone Inc.'
        else 'Unknown'
    end
{% endmacro %}

-- Usage:
-- {{ get_vendor_data('vendor_id') }} as vendor_name
```

## ğŸ“ˆ Performance Optimization

### Incremental Models

```sql
{{
  config(
    materialized='incremental',
    unique_key='trip_id',
    incremental_strategy='merge',  -- or 'append', 'delete+insert'
    partition_by={
      'field': 'pickup_datetime',
      'data_type': 'timestamp',
      'granularity': 'day'
    },
    cluster_by=['pickup_location_id', 'service_type']
  )
}}

select * from {{ ref('source_model') }}

{% if is_incremental() %}
    -- Only process new data
    where pickup_datetime > (select max(pickup_datetime) from {{ this }})
{% endif %}
```

**Benefits**:
- âœ… Processes only new/changed data
- âœ… Reduces build time from hours to minutes
- âœ… Lower compute costs
- âœ… Enables near-real-time updates

### Partitioning & Clustering

```sql
{{
  config(
    partition_by={
      'field': 'pickup_date',
      'data_type': 'date',
      'granularity': 'day'
    },
    cluster_by=['service_type', 'pickup_location_id']
  )
}}
```

**Impact**:
- 70-90% cost reduction for date-filtered queries
- Faster query performance
- Automatic partition management

## ğŸ¯ Homework Assignment

### Question 1: Green Taxi Trip Counts (October 2019)

```sql
-- Query the staging model
select count(*) as trip_count
from {{ ref('stg_green_tripdata') }}
where date(pickup_datetime) between '2019-10-01' and '2019-10-31';
```

**Answer**: See `homework/green_taxi_trip_counts_october_2019.png`

---

### Question 2: FHV Records Count

```sql
-- Count records in FHV staging model
select count(*) as fhv_record_count
from {{ ref('stg_fhv_tripdata') }};
```

**Answer**: See `homework/fhv_records_count.png`

---

### Question 3: Records in fct_monthly_zone_revenue

```sql
-- Count records in reporting model
select count(*) as revenue_record_count
from {{ ref('fct_monthly_zone_revenue') }};
```

**Answer**: See `homework/Records in fct_monthly_zone_revenue.png`

---

### Question 4: Best Performing Zone for Green Taxis (2020)

```sql
-- Find zone with highest revenue
select 
    pickup_zone,
    sum(total_revenue) as total_revenue_2020
from {{ ref('fct_monthly_zone_revenue') }}
where service_type = 'green'
  and extract(year from revenue_month) = 2020
group by pickup_zone
order by total_revenue_2020 desc
limit 1;
```

**Answer**: See `homework/best_performing_zone_for_green_taxis_2020.png`

## ğŸ’¡ dbt Best Practices

### 1. Model Naming Conventions

```
stg_<source>_<entity>.sql      # Staging: stg_yellow_tripdata.sql
int_<entity>_<verb>.sql         # Intermediate: int_trips_unioned.sql
fct_<entity>.sql                # Fact: fct_trips.sql
dim_<entity>.sql                # Dimension: dim_zones.sql
rpt_<entity>.sql                # Report: rpt_monthly_revenue.sql
```

### 2. Model Organization

```
models/
â”œâ”€â”€ staging/          # 1:1 with source tables
â”œâ”€â”€ intermediate/     # Business logic, not exposed to BI
â””â”€â”€ marts/           # Analytics-ready, exposed to BI
    â”œâ”€â”€ core/        # Shared across business units
    â”œâ”€â”€ finance/     # Finance-specific
    â””â”€â”€ marketing/   # Marketing-specific
```

### 3. Documentation

```yaml
models:
  - name: fct_trips
    description: |
      **Fact table containing all taxi trips**
      
      This table combines yellow, green, and FHV taxi data with enriched
      location information from dim_zones. Updated incrementally daily.
      
      **Grain**: One row per trip
      **Refresh**: Daily at 2 AM UTC
      **Owner**: Analytics Team
    
    columns:
      - name: trip_id
        description: "Unique trip identifier (MD5 hash of composite key)"
        tests:
          - unique
          - not_null
```

### 4. Testing Strategy

```yaml
# Test pyramid: More tests at lower layers

staging/          # Heavy testing (data quality)
  - not_null
  - unique
  - accepted_values
  - relationships

intermediate/     # Business logic testing
  - custom tests
  - expression_is_true

marts/           # Light testing (already tested upstream)
  - unique
  - not_null (key columns only)
```

### 5. Version Control

```bash
# .gitignore
target/
dbt_packages/
logs/
*.pyc
.env

# Commit strategy
git add models/
git commit -m "feat: add monthly revenue reporting model"

# Use branches for development
git checkout -b feature/new-model
# ... develop ...
git push origin feature/new-model
# Create pull request for review
```

## ğŸ› Common Issues & Solutions

### Issue 1: Model Not Found

```bash
# Error: Could not find model 'stg_yellow_tripdata'

# Solution: Check ref() syntax
{{ ref('stg_yellow_tripdata') }}  # âœ… Correct
{{ ref('staging.stg_yellow_tripdata') }}  # âŒ Wrong (no schema prefix)

# Verify model exists
ls models/staging/stg_yellow_tripdata.sql
```

### Issue 2: Circular Dependency

```bash
# Error: Circular dependency detected

# Solution: Review model dependencies
dbt list --select +fct_trips+

# Refactor to remove circular reference
# Models should flow: staging â†’ intermediate â†’ marts
```

### Issue 3: Incremental Model Not Updating

```bash
# Problem: Incremental model not picking up new data

# Solution 1: Full refresh
dbt run --select fct_trips --full-refresh

# Solution 2: Check incremental logic
{% if is_incremental() %}
    where pickup_datetime > (select max(pickup_datetime) from {{ this }})
{% endif %}

# Solution 3: Verify unique_key
config(unique_key='trip_id')  # Must be truly unique
```

### Issue 4: Test Failures

```bash
# Error: Test failed: unique_trip_id

# Debug: Run model and inspect
dbt run --select int_trips
dbt test --select int_trips

# Find duplicates
select trip_id, count(*)
from dbt_gabriel.int_trips
group by trip_id
having count(*) > 1;

# Fix: Adjust surrogate key generation
{{ dbt_utils.generate_surrogate_key(['vendor_id', 'pickup_datetime', 'pickup_location_id', 'service_type']) }}
```

## ğŸ“š Learning Resources

### Official Documentation
- [dbt Documentation](https://docs.getdbt.com/)
- [dbt Best Practices](https://docs.getdbt.com/guides/best-practices)
- [dbt Discourse Community](https://discourse.getdbt.com/)

### Packages
- [dbt_utils](https://hub.getdbt.com/dbt-labs/dbt_utils/latest/)
- [dbt_expectations](https://hub.getdbt.com/calogica/dbt_expectations/latest/)
- [codegen](https://hub.getdbt.com/dbt-labs/codegen/latest/)

### Tutorials
- [dbt Learn](https://courses.getdbt.com/)
- [Analytics Engineering Guide](https://www.getdbt.com/analytics-engineering/)

## ğŸ“ Key Takeaways

### Analytics Engineering Principles
- âœ… Transform data in the warehouse (ELT, not ETL)
- âœ… Version control analytics code like software
- âœ… Test data transformations automatically
- âœ… Document models for collaboration
- âœ… Build modular, reusable components

### dbt Core Concepts
- âœ… Models are SELECT statements
- âœ… ref() creates dependencies (DAG)
- âœ… source() connects to raw data
- âœ… Macros enable code reuse
- âœ… Tests ensure data quality

### Data Modeling
- âœ… Staging: Clean and standardize
- âœ… Intermediate: Business logic
- âœ… Marts: Analytics-ready
- âœ… Facts: Transactions (large, growing)
- âœ… Dimensions: Attributes (small, stable)

### Performance
- âœ… Incremental models for large tables
- âœ… Partition by date for time-series
- âœ… Cluster by frequently filtered columns
- âœ… Materialize intermediate results
- âœ… Pre-aggregate for dashboards

## ğŸ”„ Next Steps

After mastering dbt, you're ready for:

1. **Week 5: Data Platforms** - Modern ELT with Bruin
2. **Week 6: Batch Processing** - Large-scale processing with Spark
3. **Advanced dbt**: Snapshots, exposures, metrics

---

<div align="center">

**ğŸ“– [Back to Main README](../README.md) | â¬…ï¸ [Previous: Week 3](../03-data-warehouse/README.md) | â¡ï¸ [Next: Week 5](../05-data-platforms/README.md)**

*Transformed with ğŸ”§ dbt*

</div>